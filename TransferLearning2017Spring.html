<!DOCTYPE HTML>
<html>
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transfer Learning CNN -- CSE 586 Project</title>
    <link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.5.0/pure-min.css">
    <link rel="stylesheet" type="text/css" href="content/bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="content/site.css" />
    <link rel="stylesheet" type="text/css" href="app/content/general_project.css" />

    <script src="scripts/modernizr-2.6.2.js"></script>
</head>

<body style="align-self:center;margin-left:10%;margin-right:10%;margin-top:5%">
    <!-- header -->
    <div style="text-align:center">
    <h1 style="align-content:center"><strong>Transferred Learning of CNN</strong></h1>
    <h4 style="align-content:center"> CSE 586, Spring 2017</h4>
    <h4 style="align-content:center"><u>Aiyu Cui</u>, Zipeng Cheng & Tingyu Yan</h4>
    <h4 style="align-content:center">Pennsylvania State University</h4>
       </div>


    
    <!---->
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

        </div>
        <!-- navbar-collapse start-->
        <div id="nav-menu" class="navbar-collapse collapse" role="navigation">
            <ul class="nav navbar-nav">
                <li>
                    <a href="index.html"><span class="glyphicon glyphicon-file" aria-hidden="true"></span>Introduction</a>
                </li>
                <li>
                    <a href="index.html"><span class="glyphicon glyphicon-file" aria-hidden="true"></span>Outline</a>
                </li>
                <li>
                    <a href="#select dataset"><span class="glyphicon glyphicon-file" aria-hidden="true"></span>Dataset</a>
                </li>
                <li>
                    <a href="#pre-processing data"><span class="glyphicon glyphicon-file" aria-hidden="true"></span>Pre-processing </a>
                </li>
                <li>
                    <a href="#classification"><span class="glyphicon glyphicon-file" aria-hidden="true"></span>Classification</a>
                </li>
                <li>
                    <a href="#evaluation"><span class="glyphicon glyphicon-file" aria-hidden="true"></span>Evaluation</a>
                </li>
                <li>
                    <a href="#conclustion"><span class="glyphicon glyphicon-file" aria-hidden="true"></span>Conclusion</a>
                </li>

                <li>
                    <a href="#conclustion"><span class="glyphicon glyphicon-file" aria-hidden="true"></span>References</a>
                </li>
            </ul>
        </div>
    </div>
    </div>


    <!-- navbar-collapse end-->
    <ul>
        <li>
            <section id="introduction">
                <div class="section_title">
                    <h2><strong>Introduction</strong></h2>
                    <div class="section_body">
                        <p>In this project, we demonstrate how to solve simple object recognition problem by using transfer learning of convolutional neural network (CNN). We use pre-trained CNN to preprocess the dataset in terms of fine-tuning. Then we use the preprocessed the data to train classifiers to solve the object recognition problems. We retrain the CNN by insert SVM and MLP layers. Classification accuracy and confusion matrix are used to evaluate the performance of our classifiers. Our creative ideas and results will be presented in detail in the following parts.</p>
                        <p>Our experiment is run on Matlab. We use pre-trained CNN from CNN framework from Matconvnet [2]. The dataset we work with is Caltech 101 [1].</p>
                    </div>
                </div>
            </section>
        </li>


        <li>
            <section id="introduction">
                <div class="section_title">
                    <h2><strong>Experiment Outline</strong></h2>
                    <div class="section_body">
                        Our classification is designed in the following steps:
                        <ol>
                            <li>Partition dataset into training data and test data
3.	</li>
                            <li>Pre-process all the images (input) but put them into pre-trained CNN extract the full-connected layers as the processed the data</li>
                            <li>Use the processed data to train classifiers and evaluate the result.</li>
                        </ol>
                                      </div>
                </div>
            </section>
        </li>




        <li>
            <section id="select dataset">
                <div class="section_title">
                    <h2>
                        <strong>Select Dataset (Images)</strong></h3>
                        <div class="section_body">
                            <p>In this experiment, our data are from Caltech 101 [1], which is an image dataset with 101 categories. We select four species of animals for our object classification experiments: kangaroo, flamingo, crayfish and hawksbill and partition them as training set and test set with ratio 1:2. Our final image dataset is formed as:</p>
                        </div>
                        <div class="col-md-12 col-sm-3 col-xs-12">
                            <img src="images/tansferCNN2017/8.png">
                        </div>
                        <div class="clearfix"></div>
                        <p>(Table 1: dataset partition table)</p>
                        <br></br>
                        <div class="col-md-3 col-sm-3 col-xs-12">
                            <img src="images/tansferCNN2017/1.png" alt="">
                        </div>
                        <div class="col-md-3 col-sm-3 col-xs-12">
                            <img src="images/tansferCNN2017/2.png" alt="">
                        </div>
                        <div class="col-md-3 col-sm-3 col-xs-12">
                            <img src="images/tansferCNN2017/3.png" alt="">
                        </div>
                        <div class="col-md-3 col-sm-3 col-xs-12">
                            <img src="images/tansferCNN2017/4.png" alt="">
                        </div><br />
                        <p>(Fig. 1, 2, 3 & 4: Sample image of kangaroo, flamingo, crayfish and hawksbill respectively)</p>
                            <p>Source Code of constructing and partitioning dataset available at:
                                <a href="https://github.com/cuiaiyu/transferLearningCNN/blob/master/setupDatasets.m">
                                    https://github.com/cuiaiyu/transferLearningCNN/blob/master/setupDatasets.m
                                </a>
                            </p>
                </div>
            </section>

        </li>
        <li>


            <section id="pre-processing data">
                <div class="section_title">
                    <h2><strong>Pre-processing Data (Fine-Tuning)</strong></h2>
                    <div class="section_body">

                        <p>For every image we use (for both the training data and test data), we preprocess the image through the following steps:</p>
                        <ul>
                            <li>
                                1.	Normalize the input image into size 224x224x3;
                            </li>
                            <li>2.	Put the image into the pre-trained CNN MatConvNet [2] as input, and run MatConvNet forwards;</li>
                            <li>3.	Extract the fully-connected layer (1x4096) out of the pre-trained CNN result, and this fully-connected layer (1x4096) is going to be our pre-processed image.</li>
                            <li>After these steps, all the images in our dataset are converted into 1x4096 vectors and we will then use them to train and test our classifiers.</li>
                            <p>
                                Source code for extracting features available at:
                                <a href="https://github.com/cuiaiyu/transferLearningCNN/blob/master/extractFeatures.m">
                                    https://github.com/cuiaiyu/transferLearningCNN/blob/master/extractFeatures.m
                                </a>
                            </p>
                    </div>
                </div>
            </section>


        </li>
        <li>


            <section id="classification">
                <div class="section_title">
                    <h2><strong>Classification</strong></h2>
                    <div class="section_body">

                        <p>We tried different classification methods with the processed data. We first try binary classification for kangaroo vs. Flamingo by using Support Vector Machine (SVM) and Multilayer Perceptron (MLP). And then we extends our experiments to multiclass classification by MLP. </p>
                        <p class="cmpny1">In this section, we describe how we set up the experiment for each model of classifier. In next section, we show the experiment result in details.</p>
                        <ul>
                            <li>

                                <div class="section_body_sub">
                                    <h3><strong>A.	SVM</strong></h3>
                                    <p>We only use SVM to do the binary classification problem. We simply use the Matlab built-in toolbox of SVM by feeding in our processed data (1x4096 vectors).</p>
                                    <p>
                                        Source code available: <a href="https://github.com/cuiaiyu/transferLearningCNN/blob/master/simplesvm.m">
                                            https://github.com/cuiaiyu/transferLearningCNN/blob/master/simplesvm.m
                                        </a>
                                    </p>
                                </div>
                            </li>

                            <li>
                                <div class="section_body_sub">
                                    <h3><strong>B.	MLP</strong></h3>
                                    <p>Then we try another classifier, MLP. We train MLPs for 2-class, 3-class, and 4-class classification problems with the 1x4096 vectors as data input. </p>
                                    <p>To find a best accuracy, for each classification problem, we train MLPs with different number of hidden layers from 1 to 20 For each experiment, we repeat 20 times and take average of the error rate, because the random initializations.</p>
                                    <p>We also use the Matlab built-in toolbox for MLP by setting the configuration as: </p>
                                    <ul>
                                        <li>a.	Training function: resilient backpropagation</li>
                                        <li>b.	Performance measurement: mean square error (MSE)</li>
                                    </ul>
                                    <p>
                                        Source Code available: <a href="<p>Source Code available: <a href =
				  https://github.com/cuiaiyu/transferLearningCNN/blob/master/simpleNN.m">
                                            https://github.com/cuiaiyu/transferLearningCNN/blob/master/simpleNN.m
                                        </a>
                                    </p>

                                </div>
                            </li>
                        </ul>
                    </div>
            </section>

        </li>
        <li>


            <section id="evaluation">
                <div class="section_title">
                    <h3><strong>Evaluations</strong></h3>



                    <div class="section_body_sub">

                        <ul>
                            <li>
                                <h3><strong>A.	Binary classification<span>(Kangaroo vs. Flamingo)</span></strong></h3>
                                <p>First, we only consider the two-class classification problem: kangaroo vs. flamingo. We apply two methods to achieve this classification: Support Vector Machine (SVM) and Multilayer Perceptron (MLP).</p>

                                <ul>
                                    <li>
                                        <div class="section_body_sub2">
                                            <h4><strong>a.	Support Vector Machine (SVM)</strong></h4>
                                            <p>We first train a SVM by the Matlab built-in SVM toolbox. In the SVM experiment, with the test set we achieve an accuracy of 98.04% and confusion matrix: </p>

                                            <img src="images/tansferCNN2017/9.png" alt="">
                                            <p>(Table 2: Confusion matrix for SVM)</p>
                                        </div>
                                    </li>

                                    <li>

                                        <div class="section_body_sub2">
                                            <h4><strong>b.	Multilayer Perceptron (MLP)</strong></h4>
                                            <p>We also train a MLP to solve the two-class classification problem. We train MLP with different number of hidden layers from 1 to 20 with the training set. For each number of hidden layers, we compute the error rate on the test set. Then we repeat the experiment 20 times and take the average of error rate, because the MLP is initialized randomly. We finally get result as following:</p>
                                            <div class="bounceInLeft">
                                                <img style="width:40%;height:40%" src="/images/tansferCNN2017/5.png" alt="">

                                                (Fig. 5: Average error rate vs. # of hidden layers for 2-class)
                                                <br>
                                            </div>
                                            <div class="bounceInRight">
                                                <p>From the above result, we can roughly see that there is no big difference between the performance between SVM and MLP of the 2-class problem with the features extracted from a pre-trained CNN.</p>
                                                <br></br>
                                            </div>
                                        </div>
                                    </li>
                                </ul>


                            <li>
                                <div class="section_body_sub">
                                    <h3><strong>B.	Multi-class classification</strong></h3>
                                    <p>After we tried binary classification problem, right now we are moving to work on multi-class classification. We try three-class and four-class classification by using multilayer perceptron (MLP). Same idea as above, we try different # of hidden layers from 1-20, and repeat the experiments for 20 times for both three-class and four-class classification.</p>

                                    <ul>
                                        <li>
                                            <div class="section_body_sub2">
                                                <h4><strong>a.	Three-class classification (Kangaroo vs. Flamingo vs. Crayfish)</strong></h4>
                                                <p>We train and test the MLP as described above, which gives the following result:</p>

                                                <div class="bounceInLeft">
                                                    <img src="images/tansferCNN2017/11.png" alt="">
                                                    (Fig. 6: Average error rate vs. # of hidden layers for 3-class)
                                                </div>
                                                <div class="bounceInRight">
                                                    <p>As shown in the pictures, the best # of hidden layer is around 9 which could give us an accuracy around 0.9. So we set the # of hidden layer to be 9 and run the experiment again, we get the following confusion matrix:</p>
                                                    <p><img src="images/tansferCNN2017/12.png" alt=""></p></br>
                                                    (Table 3: Confusion matrix for MLP with 9 hidden layers of 3-class)</p>
                                                    </br>
                                                </div>
                                            </div>
                                        </li>

                                        <li>


                                            <div class="section_body_sub2">
                                                <h4><strong>b.	Four-class classification (Kangaroo vs. Flamingo vs. Crayfish vs. Hawksbill)</strong></h4>
                                                <p>We perform the same training and testing steps as those of 2-classes and 3-class classification. We get performance like:</p>

                                                <div class="bounceInLeft">
                                                    <img src="images/tansferCNN2017/13.png" alt="">(Fig. 7: Average error rate vs. # of hidden layers for 4-class)
                                                </div>
                                                <div class="bounceInRight">
                                                    </br>
                                                    <p>As shown, the best # of hidden layer is around 11, which could give an accuracy of ~0.8. Therefore, we fix the # of hidden layer as 11, and compute the confusion matrix, which is the chart below:</p>
                                                </div>

                                                <p><img src="images/tansferCNN2017/14.png" alt=""></p></br>
                                                (Table 4: Confusion matrix for MLP with 11 hidden layers of 4-class)</p>
                                            </div>
                                        </li>
                                    </ul>
                                </div>
                            </li>
        </li>
    </ul>

    <p>From our experiments, we find that with the increasing of # of categories, the accuracy of MLPs decreases. Also, with the increasing of # of categories, the more hidden layers is needed to get a better accuracy. This makes sense because the more categories, the more ambiguous and complex the classification problem becomes. However, we will still need more experiments to prove that. </p>
    </div>
    </div>
    </section>



    </li>
    <li>


        <section id="conclustion">
            <div class="section_title">
                <h2><strong>Conclusion</strong></h2>
                <div class="section_body">
                    <p>In this experiment, we demo that the transfer learning method and show that transfer learning work well with SVM and MLP. A major drawback of this experiment is the dataset we selected is small, so the result is not general enough. For the future work, we would like to try a large dataset and more classes to see what will happen.</p>
                </div>
            </div>
        </section>

    </li>
    <li>
        <section id="References">
            <div class="section_title">
                <h2><strong>References</strong></h2>
                <div class="section_body">
                    <ol>
                        <li>
                            <a href="http://www.vision.caltech.edu/Image_Datasets/Caltech101/">
                                http://www.vision.caltech.edu/Image_Datasets/Caltech101/
                            </a>
                        </li>
                        <li><a href="http://www.vlfeat.org/matconvnet/pretrained/">http://www.vlfeat.org/matconvnet/pretrained/</a></li>
                    </ol>
                </div>
            </div>
        </section>

    </li>
    </ul>


    </div>
    <!---->

    <footer>
        <p>&copy; Copyright 2017 - Aiyu Cui, Zipeng Chen & Tingyu Yan</p>
    </footer>
</body>
</html>